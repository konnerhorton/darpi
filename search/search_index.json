{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Don't Accept Risk, Price It!","text":"<p>Construction projects (especially large ones) often involve risk registers. One of the function of these risk registers is to determine how much each risk is expected to cost. This package is intended to provide some simple tools to help price risks on your project.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install this package from GitHub, you can use <code>pip</code> with the GitHub repository URL. Follow the steps below:</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p>Ensure you have Python and pip installed on your machine. You can download Python from python.org. Pip is included with Python 3.4 and later.</p>"},{"location":"#installation_1","title":"Installation","text":""},{"location":"#clone-the-repository","title":"Clone the repository","text":"<p>You can clone the repository to your local machine using the following command:</p> <pre><code>git clone https://github.com/konnerhorton/darpi.git\n</code></pre> <p>Alternatively, you can download the ZIP file from the GitHub page and extract it.</p>"},{"location":"#navigate-to-the-project-directory","title":"Navigate to the project directory","text":"<pre><code>cd darpi\n</code></pre>"},{"location":"#install-the-package","title":"Install the package","text":"<p>Use pip to install the package. This can be done in two ways:</p> <ul> <li> <p>Directly from the cloned repository:</p> <pre><code>pip install .\n</code></pre> </li> <li> <p>From the GitHub repository:</p> <p>You can also install the package directly from GitHub without cloning:</p> <pre><code>pip install git+https://github.com/konnerhorton/darpi.git\n</code></pre> </li> </ul>"},{"location":"#verify-installation","title":"Verify Installation","text":"<p>To verify the installation, you can try importing the package in a Python shell:</p> <pre><code>import darpi\nprint(darpi.__version__)\n</code></pre>"},{"location":"#updating-the-package","title":"Updating the Package","text":"<p>To update the package to the latest version from the GitHub repository, use the following command:</p> <pre><code>pip install --upgrade git+https://github.com/konnerhorton/darpi.git\n</code></pre>"},{"location":"#uninstallation","title":"Uninstallation","text":"<p>To uninstall the package, you can use pip:</p> <pre><code>pip uninstall darpi\n</code></pre>"},{"location":"examples/heat-maps/","title":"Heat Maps","text":"<p>Plot heatmaps to show the geometric mean of the risk scores.</p>"},{"location":"examples/heat-maps/#import-libraries","title":"Import libraries","text":"<pre><code>from darpi.qualitative.plots import plot_empty_heat_map, add_scatter_to_heat_map\n</code></pre>"},{"location":"examples/heat-maps/#generate-random-risks","title":"Generate Random Risks","text":""},{"location":"examples/heat-maps/#generate-risks","title":"Generate Risks","text":"<pre><code>import random\nimport pandas as pd\n\n\ndef generate_risks(num_risks=20):\n    risks = []\n    for i in range(num_risks):\n        risk = {\n            \"risk-id\": f\"R-{int(i + 1):03}\",\n            \"probability\": random.randint(1, 5),\n            \"schedule\": random.randint(1, 5),\n            \"cost\": random.randint(1, 5),\n        }\n        risks.append(risk)\n    return risks\n\nrisks = generate_risks()\n</code></pre>"},{"location":"examples/heat-maps/#calculate-risk-scores","title":"Calculate Risk Scores","text":"<pre><code>df = pd.DataFrame(risks)\ndf[\"impact\"] = df[[\"schedule\", \"cost\"]].max(axis=1)\ndf[\"risk-score\"] = df[\"probability\"]\ndf\n</code></pre> risk-id probability schedule cost impact risk-score R-001 4 5 1 5 20 R-002 2 4 3 4 8 R-003 1 2 2 2 2 R-004 2 1 1 1 2 R-005 1 4 1 4 4 R-006 3 1 3 3 9 R-007 1 3 5 5 5 R-008 5 4 5 5 25 R-009 3 3 4 4 12 R-010 5 3 5 5 25 R-011 3 2 4 4 12 R-012 4 5 1 5 20 R-013 2 2 4 4 8 R-014 2 3 2 3 6 R-015 1 2 3 3 3 R-016 1 4 2 4 4 R-017 4 4 2 4 16 R-018 4 2 2 2 8 R-019 1 3 3 3 3 R-020 3 5 4 5 15"},{"location":"examples/heat-maps/#find-the-count-for-each-impact-probability-combination","title":"Find the Count for Each impact-probability Combination","text":"<pre><code>df = (\n    df[[\"risk-id\", \"probability\", \"impact\"]]\n    .groupby([\"probability\", \"impact\"])\n    .agg(\"count\")\n    .reset_index()\n    .rename(columns={\"risk-id\": \"counts\"})\n)\ndf\n</code></pre> probability impact counts 1 2 1 1 3 2 1 4 2 1 5 1 2 1 1 2 3 1 2 4 2 3 3 1 3 4 2 3 5 1 4 2 1 4 4 1 4 5 2 5 5 2"},{"location":"examples/heat-maps/#send-to-records-for-plotting","title":"Send to Records for Plotting","text":"<pre><code>risk_score_counts = df.to_dict(\"records\")\nrisk_score_counts\n\n[{'probability': 1, 'impact': 2, 'counts': 1},\n {'probability': 1, 'impact': 3, 'counts': 2},\n {'probability': 1, 'impact': 4, 'counts': 2},\n {'probability': 1, 'impact': 5, 'counts': 1},\n {'probability': 2, 'impact': 1, 'counts': 1},\n {'probability': 2, 'impact': 3, 'counts': 1},\n {'probability': 2, 'impact': 4, 'counts': 2},\n {'probability': 3, 'impact': 3, 'counts': 1},\n {'probability': 3, 'impact': 4, 'counts': 2},\n {'probability': 3, 'impact': 5, 'counts': 1},\n {'probability': 4, 'impact': 2, 'counts': 1},\n {'probability': 4, 'impact': 4, 'counts': 1},\n {'probability': 4, 'impact': 5, 'counts': 2},\n {'probability': 5, 'impact': 5, 'counts': 2}]\n</code></pre>"},{"location":"examples/heat-maps/#plot-the-heatmap","title":"Plot the Heatmap","text":"<pre><code>fig = add_scatter_to_heat_map(risk_score_counts, \"Some risks on a heatmap\")\nfig.write_image(\"heat-map.png\")\nfig.show()\n</code></pre>"},{"location":"examples/multiple-risks/","title":"Multiple Risk","text":"<p>Determine non-exceedence probabilities for a multiple risks.</p>"},{"location":"examples/multiple-risks/#import-libraries","title":"Import libraries","text":"<pre><code>import sys\nimport os\n\nimport pandas as pd\n\nfrom darpi.quantitative.plots import plot_histogram_and_cdf, plot_ppf_curve\nfrom darpi.quantitative.probability import (\n    get_histogram_data,\n    get_samples,\n    get_triangular_distribution,\n    get_empirical_cdf,\n    get_empirical_ppf,\n    sum_samples,\n)\nfrom darpi.qualitative.plots import plot_empty_heat_map, add_scatter_to_heat_map\n</code></pre>"},{"location":"examples/multiple-risks/#generate-probability-of-non-exceedance-charts-for-multiple-risks","title":"Generate probability of non-exceedance charts for multiple risks","text":"<pre><code># Identify some risks\nrisks = {\n    \"Risk 1\": {\"costs\": (1000, 2000, 5000), \"probability\": 0.6},\n    \"Risk 2\": {\"costs\": (2000, 4000, 8000), \"probability\": 0.8},\n    \"Risk 3\": {\"costs\": (2800, 4000, 10000), \"probability\": 0.5},\n}\n\n# Get samples for each risk\nfor risk, details in risks.items():\n    a, c, b = details[\"costs\"]\n    risk_probability = details[\"probability\"]\n    distribution = get_triangular_distribution(a, b, c)\n    data = get_samples(distribution=distribution, risk_probability=risk_probability)\n    risks[risk][\"samples\"] = data\n\n# Get summed data\ndata = sum_samples([risk[\"samples\"] for risk in risks.values()])\n\n# Get plotting data\nhist_data = get_histogram_data(data)\ncdf_data = get_empirical_cdf(data)\nppf_data = get_empirical_ppf(data)\n\n# Make some plots\nfig = plot_histogram_and_cdf(hist_data=hist_data, cdf_data=cdf_data)\nfig.write_image(\"..images/multiple-risk-histogram_cdf.png\")\nfig = plot_ppf_curve(data=ppf_data)\nfig.write_image(\"..images/multiple-risk-ppf.png\")\n</code></pre>"},{"location":"examples/multiple-risks/#generate-probability-of-non-exceedance-table-for-multiple-risks","title":"Generate probability of non-exceedance table for multiple risks","text":"<pre><code>get_non_exceedance_table(data).round(2)\n</code></pre> cost p 0 0.00 0.00 1 0.00 0.01 2 0.00 0.02 3 0.00 0.03 4 0.00 0.04 ... ... ... 96 15155.18 0.96 97 15579.32 0.97 98 16108.59 0.98 99 16887.59 0.99 100 21930.77 1.00 <p>101 rows \u00d7 2 columns</p>"},{"location":"examples/single-risk/","title":"Single Risk","text":"<p>Determine non-exceedence probabilities for a single risk.</p>"},{"location":"examples/single-risk/#import-libraries","title":"Import libraries","text":"<pre><code>import sys\nimport os\n\nimport pandas as pd\n\nfrom darpi.quantitative.plots import plot_histogram_and_cdf, plot_ppf_curve\nfrom darpi.quantitative.probability import (\n    get_histogram_data,\n    get_samples,\n    get_triangular_distribution,\n    get_empirical_cdf,\n    get_empirical_ppf,\n    sum_samples,\n)\nfrom darpi.qualitative.plots import plot_empty_heat_map, add_scatter_to_heat_map\n</code></pre>"},{"location":"examples/single-risk/#generate-probability-of-non-exceedance-charts-for-one-risk","title":"Generate probability of non-exceedance charts for one risk","text":"<pre><code># Identify the risk, cost, and probability of occurrence\nrisk = \"Risk 1\"\ncosts = (1000, 2000, 5000)\nprobability = 0.6\n\n# Generate the triangular distribution that corresponds with the risk above\ndistribution = get_triangular_distribution(a=costs[0], b=costs[2], c=costs[1])\n\n# Generate the samples (the default is n==100,000)\ndata = get_samples(distribution=distribution, risk_probability=probability)\n\n# Get plotting data\nhist_data = get_histogram_data(data)\ncdf_data = get_empirical_cdf(data)\nppf_data = get_empirical_ppf(data)\n\n# Make some plots\nfig = plot_histogram_and_cdf(hist_data=hist_data, cdf_data=cdf_data)\n# fig.write_image(\"images/single-risk-histogram_cdf.png\")\nfig = plot_ppf_curve(data=ppf_data)\n# fig.write_image(\"images/single-risk-ppf.png\")\n</code></pre>"},{"location":"examples/single-risk/#generate-probability-of-non-exceedance-table-for-one-risk","title":"Generate probability of non-exceedance table for one risk","text":"<pre><code>get_non_exceedance_table(data).round(2)\n</code></pre> cost p 0 0.00 0.00 1 0.00 0.01 2 0.00 0.02 3 0.00 0.03 4 0.00 0.04 ... ... ... 96 4099.60 0.96 97 4224.11 0.97 98 4365.02 0.98 99 4554.38 0.99 100 4987.99 1.00 <p>101 rows \u00d7 2 columns</p>"},{"location":"qualitative/qualitative_plots/","title":"<code>plots</code>","text":""},{"location":"qualitative/qualitative_plots/#darpi.qualitative.plots.plot_empty_heat_map","title":"<code>plot_empty_heat_map(low=1, high=5)</code>","text":"<p>Creates an empty heat map with customizable axis range and color scale.</p> Parameters: <p>low : int, optional     The lower bound of the axis range, by default 1. high : int, optional     The upper bound of the axis range, by default 5.</p> Returns: <p>go.Figure     A Plotly figure object representing the empty heat map.</p> Source code in <code>darpi/qualitative/plots.py</code> <pre><code>def plot_empty_heat_map(low: int = 1, high: int = 5) -&gt; go.Figure:\n    \"\"\"\n    Creates an empty heat map with customizable axis range and color scale.\n\n    Parameters:\n    -----------\n    low : int, optional\n        The lower bound of the axis range, by default 1.\n    high : int, optional\n        The upper bound of the axis range, by default 5.\n\n    Returns:\n    --------\n    go.Figure\n        A Plotly figure object representing the empty heat map.\n    \"\"\"\n    axis_range = [low - 0.5, high + 0.5]\n    array = np.linspace(axis_range[0], axis_range[1])\n\n    custom_color_scale = [\n        [0.0, \"green\"],\n        [0.1, \"yellow\"],\n        [1.0, \"red\"],\n    ]\n\n    res = np.outer(array, array)\n\n    fig = go.Figure(\n        data=go.Contour(\n            z=res,\n            x=array,\n            y=array,\n            contours=dict(coloring=\"heatmap\"),\n            colorscale=custom_color_scale,\n            line_width=0,\n            showscale=False,\n        )\n    ).update(\n        layout=dict(\n            height=600,\n            width=600,\n            xaxis=dict(\n                title=dict(text=\"Probability of Occurrence\", font_size=18),\n                range=axis_range,\n                mirror=True,\n                constrain=\"domain\",\n                showgrid=False,\n                tickfont=dict(size=16),\n            ),\n            yaxis=dict(\n                title=dict(text=\"Impact\", font_size=18),\n                range=axis_range,\n                mirror=True,\n                constrain=\"domain\",\n                scaleanchor=\"x\",\n                scaleratio=1,\n                showgrid=False,\n                tickfont=dict(size=16),\n            ),\n        )\n    )\n\n    grid_lines = np.arange(axis_range[0], axis_range[1])[1:]\n    for i in grid_lines:\n        fig.add_vline(x=i, line=dict(color=\"black\", width=2))\n        fig.add_hline(y=i, line=dict(color=\"black\", width=2))\n\n    return fig\n</code></pre>"},{"location":"qualitative/qualitative_plots/#darpi.qualitative.plots.add_scatter_to_heat_map","title":"<code>add_scatter_to_heat_map(risk_score_counts, title)</code>","text":"<p>Adds a scatter plot to the heat map, representing risks with their impact and probability.</p> Parameters: <p>risks : List[Dict[str, Any]]     A list of dictionaries where each dictionary contains 'impact', 'probability',     and 'counts' keys, representing the risk's impact, probability, and occurrence count. title : str     The title of the resulting heat map with scatter plot.</p> Returns: <p>go.Figure     A Plotly figure object representing the heat map with the added scatter plot.</p> Source code in <code>darpi/qualitative/plots.py</code> <pre><code>def add_scatter_to_heat_map(\n    risk_score_counts: list[dict[str, float]], title: str\n) -&gt; go.Figure:\n    \"\"\"\n    Adds a scatter plot to the heat map, representing risks with their impact and probability.\n\n    Parameters:\n    -----------\n    risks : List[Dict[str, Any]]\n        A list of dictionaries where each dictionary contains 'impact', 'probability',\n        and 'counts' keys, representing the risk's impact, probability, and occurrence count.\n    title : str\n        The title of the resulting heat map with scatter plot.\n\n    Returns:\n    --------\n    go.Figure\n        A Plotly figure object representing the heat map with the added scatter plot.\n    \"\"\"\n    impacts = np.array([risk[\"impact\"] for risk in risks])\n    probabilities = np.array([risk[\"probability\"] for risk in risks])\n    counts = np.array([risk[\"counts\"] for risk in risks])\n\n    gmean_prob = (probabilities * counts).sum() / counts.sum()\n    gmean_impact = (impacts * counts).sum() / counts.sum()\n    max_count = max(counts)\n\n    marker_size = 12\n    sizeref = (max_count / (marker_size**2)) / 12\n    mean_label_offset = 0.2\n\n    scatter = go.Scatter(\n        x=probabilities,\n        y=impacts,\n        text=counts,\n        textfont=dict(size=14),\n        mode=\"markers+text\",\n        hoverinfo=\"none\",\n        showlegend=False,\n        marker=dict(\n            size=counts,\n            sizemode=\"area\",\n            sizeref=sizeref,\n            color=\"#63967D\",\n            opacity=1,\n        ),\n    )\n\n    fig = plot_empty_heat_map()\n    fig.add_trace(scatter).add_trace(\n        go.Scatter(\n            x=[gmean_prob],\n            y=[gmean_impact],\n            marker=dict(\n                symbol=\"cross\",\n                size=16,\n                color=\"red\",\n            ),\n            showlegend=False,\n        )\n    ).add_annotation(\n        text=f\"&lt;b&gt;P:{gmean_prob:.2f}, I:{gmean_impact:.2f}&lt;/b&gt;\",\n        font=dict(size=14),\n        x=gmean_prob,\n        y=gmean_impact - mean_label_offset,\n        showarrow=False,\n    ).update(\n        layout=dict(title=dict(text=title, font=dict(size=18)))\n    )\n\n    return fig\n</code></pre>"},{"location":"quantitative/quantitative_plots/","title":"<code>plots</code>","text":""},{"location":"quantitative/quantitative_plots/#darpi.quantitative.plots.plot_histogram_and_cdf","title":"<code>plot_histogram_and_cdf(hist_data, cdf_data)</code>","text":"<p>Plot the histogram and cumulative distribution function using Plotly.</p> <p>Parameters:</p> Name Type Description Default <code>hist_data</code> <code>HistogramData</code> <p>Data for the histogram containing bin centers and relative frequencies.</p> required <code>cdf_data</code> <code>CDFData</code> <p>Data for the cumulative distribution function containing x and y values.</p> required <p>Returns:</p> Type Description <code>Figure</code> <p>Plotly figure object with the histogram and CDF.</p> Source code in <code>darpi/quantitative/plots.py</code> <pre><code>def plot_histogram_and_cdf(hist_data: HistogramData, cdf_data: CDFData) -&gt; go.Figure:\n    \"\"\"\n    Plot the histogram and cumulative distribution function using Plotly.\n\n    Parameters\n    ----------\n    hist_data : HistogramData\n        Data for the histogram containing bin centers and relative frequencies.\n    cdf_data : CDFData\n        Data for the cumulative distribution function containing x and y values.\n\n    Returns\n    -------\n    go.Figure\n        Plotly figure object with the histogram and CDF.\n    \"\"\"\n    hist_x, hist_y = hist_data\n    cdf_x, cdf_y = cdf_data\n    max_hist_y = max(hist_y)\n    min_hist_x, max_hist_x = min(hist_x), max(hist_x)\n    fig = go.Figure()\n\n    # Add histogram\n    fig.add_trace(\n        go.Bar(\n            x=hist_x,\n            y=hist_y,\n            name=\"Relative frequency\",\n            opacity=0.75,\n            yaxis=\"y1\",\n        )\n    )\n\n    # Add cumulative distribution line\n    fig.add_trace(\n        go.Scatter(\n            x=cdf_x,\n            y=cdf_y,\n            name=\"Cumulative distribution\",\n            mode=\"lines\",\n            yaxis=\"y2\",\n        )\n    )\n\n    # Update layout\n    fig.update_layout(\n        height=500,\n        width=800,\n        title=\"Cumulative Distribution Function Curve\",\n        xaxis=dict(title=\"Cost, $\", range=[min_hist_x, max_hist_x], showgrid=False),\n        yaxis=dict(\n            title=\"Relative frequency\",\n            side=\"left\",\n            range=[0, max_hist_y * 1.1],\n            tickformat=\".2%\",\n            showgrid=False,\n        ),\n        yaxis2=dict(\n            title=\"Probability that value is not exceeded\",\n            side=\"right\",\n            overlaying=\"y\",\n            range=[0, 1],\n            tickformat=\".0%\",\n            showgrid=False,\n        ),\n        showlegend=False,\n        bargap=0.1,\n    )\n\n    return fig\n</code></pre>"},{"location":"quantitative/quantitative_plots/#darpi.quantitative.plots.plot_ppf_curve","title":"<code>plot_ppf_curve(data)</code>","text":"<p>Plot the PPF (Percent-Point Function) curve using Plotly.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>LorenzData</code> <p>Data containing binned sample values and their cumulative percentages.</p> required <p>Returns:</p> Type Description <code>Figure</code> <p>Plotly figure object with the PPF curve.</p> Source code in <code>darpi/quantitative/plots.py</code> <pre><code>def plot_ppf_curve(data: PPFData) -&gt; go.Figure:\n    \"\"\"\n    Plot the PPF (Percent-Point Function) curve using Plotly.\n\n    Parameters\n    ----------\n    data : LorenzData\n        Data containing binned sample values and their cumulative percentages.\n\n    Returns\n    -------\n    go.Figure\n        Plotly figure object with the PPF curve.\n    \"\"\"\n    # TODO make function for user to input min, max, ml and plot this (instead of the intermediate steps)\n    p_bars = np.linspace(0, 1, 21)\n    default_bar_color = \"#5799C6\"\n    p_bar_color = \"#FF7F0E\"\n    colors = [p_bar_color if x in p_bars else default_bar_color for x in data.p]\n    fig = go.Figure()\n\n    fig.add_trace(\n        go.Bar(\n            x=data.p,\n            y=data.cost,\n            name=\"Percent-Point Function Curve\",\n            marker_color=colors,\n            opacity=0.75,\n        )\n    )\n    fig.update_layout(\n        height=500,\n        width=800,\n        title=\"Percent-Point Function Curve\",\n        xaxis=dict(title=\"Probability that value is not exceeded\", range=[0, 1]),\n        yaxis=dict(title=\"Cost, $\"),\n    )\n\n    return fig\n</code></pre>"},{"location":"quantitative/quantitative_probability/","title":"<code>probability</code>","text":""},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.get_triangular_distribution","title":"<code>get_triangular_distribution(a, b, c)</code>","text":"<p>Generate a triangular distribution given the mode and the range.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>The lower bound of the distribution.</p> required <code>b</code> <code>float</code> <p>The upper bound of the distribution.</p> required <code>c</code> <code>float</code> <p>The mode of the distribution (must be between <code>a</code> and <code>b</code>).</p> required <p>Returns:</p> Type Description <code>rv_continuous</code> <p>A frozen <code>rv_continuous</code> object representing the triangular distribution.</p> Notes <p>The triangular distribution is defined by three parameters: - <code>a</code> is the minimum value, - <code>b</code> is the maximum value, - <code>c</code> is the mode (the peak of the distribution).</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def get_triangular_distribution(a: float, b: float, c: float) -&gt; rv_continuous:\n    \"\"\"\n    Generate a triangular distribution given the mode and the range.\n\n    Parameters\n    ----------\n    a : float\n        The lower bound of the distribution.\n    b : float\n        The upper bound of the distribution.\n    c : float\n        The mode of the distribution (must be between `a` and `b`).\n\n    Returns\n    -------\n    rv_continuous\n        A frozen `rv_continuous` object representing the triangular distribution.\n\n    Notes\n    -----\n    The triangular distribution is defined by three parameters:\n    - `a` is the minimum value,\n    - `b` is the maximum value,\n    - `c` is the mode (the peak of the distribution).\n    \"\"\"\n    if not all(isinstance(v, (float, int)) for v in [a, b, c]):\n        raise TypeError(\"All inputs must be either float or int.\")\n    if not (a &lt;= c &lt;= b):\n        raise ValueError(f\"Value {c} is out of range. It must be between {a} and {b}.\")\n    range_val = b - a\n    c_shape = (c - a) / range_val\n    return stats.triang(c=c_shape, loc=a, scale=range_val)\n</code></pre>"},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.get_samples","title":"<code>get_samples(distribution, risk_probability)</code>","text":"<p>Generate samples from a given distribution based on a risk probability.</p> <p>Parameters:</p> Name Type Description Default <code>distribution</code> <code>rv_continuous</code> <p>A frozen <code>rv_continuous</code> object from which samples are to be drawn.</p> required <code>risk_probability</code> <code>float</code> <p>The probability of risk occurrence, determining the proportion of non-zero samples.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of samples, where a portion of the samples is drawn from the distribution and the remainder are zeros, based on the risk probability.</p> Notes <p>The number of samples is determined by a constant <code>ITERATIONS</code>.</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def get_samples(distribution: rv_continuous, risk_probability: float) -&gt; np.ndarray:\n    \"\"\"\n    Generate samples from a given distribution based on a risk probability.\n\n    Parameters\n    ----------\n    distribution : rv_continuous\n        A frozen `rv_continuous` object from which samples are to be drawn.\n    risk_probability : float\n        The probability of risk occurrence, determining the proportion of non-zero samples.\n\n    Returns\n    -------\n    np.ndarray\n        An array of samples, where a portion of the samples is drawn from the distribution\n        and the remainder are zeros, based on the risk probability.\n\n    Notes\n    -----\n    The number of samples is determined by a constant `ITERATIONS`.\n    \"\"\"\n    if isinstance(risk_probability, (float, int)) == False:\n        raise TypeError(\"All inputs must be either float or int.\")\n\n    if not 0 &lt;= risk_probability &lt;= 1:\n        raise ValueError(\"`risk_probability` must be between `0` and `1`\")\n\n    samples = np.zeros(ITERATIONS)\n    occurrences = int(ITERATIONS * risk_probability)\n    samples[0:occurrences] = distribution.rvs(occurrences)\n    np.random.shuffle(samples)\n    return samples\n</code></pre>"},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.sum_samples","title":"<code>sum_samples(sample_sets)</code>","text":"<p>Sum multiple sets of samples element-wise.</p> <p>Parameters:</p> Name Type Description Default <code>sample_sets</code> <code>list of np.ndarray</code> <p>A list of sample arrays to be summed.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array representing the element-wise sum of the input sample arrays.</p> Notes <p>All arrays in <code>sample_sets</code> must have the same shape.</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def sum_samples(sample_sets: list[np.ndarray]) -&gt; np.ndarray:\n    \"\"\"\n    Sum multiple sets of samples element-wise.\n\n    Parameters\n    ----------\n    sample_sets : list of np.ndarray\n        A list of sample arrays to be summed.\n\n    Returns\n    -------\n    np.ndarray\n        An array representing the element-wise sum of the input sample arrays.\n\n    Notes\n    -----\n    All arrays in `sample_sets` must have the same shape.\n    \"\"\"\n    if not all(len(samples) == ITERATIONS for samples in sample_sets):\n        warnings.warn(\n            \"The length of some of your samples is not equal to the specified `ITERATIONS`, please confirm these are the samples to use.\"\n        )\n    length = len(sample_sets[0])\n    for index, samples in enumerate(sample_sets[1:]):\n        if len(samples) != length:\n            raise ValueError(\n                f\"Not all lists have the same length (sample {index+1} is different than the first).\"\n            )\n    return np.add.reduce(sample_sets)\n</code></pre>"},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.get_empirical_cdf","title":"<code>get_empirical_cdf(data)</code>","text":"<p>Calculate the empirical cumulative distribution function (CDF) for a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The data array for which to compute the empirical CDF.</p> required <p>Returns:</p> Type Description <code>CDFData</code> <p>An object containing the sorted data and corresponding cumulative probabilities.</p> Notes <p>The empirical CDF is the proportion of data points less than or equal to a given value.</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def get_empirical_cdf(data: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the empirical cumulative distribution function (CDF) for a dataset.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        The data array for which to compute the empirical CDF.\n\n    Returns\n    -------\n    CDFData\n        An object containing the sorted data and corresponding cumulative probabilities.\n\n    Notes\n    -----\n    The empirical CDF is the proportion of data points less than or equal to a given value.\n    \"\"\"\n    n = len(data)\n    p = np.arange(1, n + 1) / n\n    return CDFData(cost=np.sort(data), p=p)\n</code></pre>"},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.get_empirical_ppf","title":"<code>get_empirical_ppf(samples)</code>","text":"<p>Calculate the empirical percent-point function (PPF) for a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>ndarray</code> <p>The data array for which to compute the empirical PPF. Use <code>get_samples()</code></p> required <p>Returns:</p> Type Description <code>PPFData</code> <p>An object containing the cost values at each percentile and the corresponding percentiles.</p> Notes <p>The empirical PPF is the inverse of the empirical CDF, mapping percentiles to samples values.</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def get_empirical_ppf(samples: np.ndarray) -&gt; PPFData:\n    \"\"\"\n    Calculate the empirical percent-point function (PPF) for a dataset.\n\n    Parameters\n    ---------\n    samples : np.ndarray\n        The data array for which to compute the empirical PPF. Use `get_samples()`\n\n    Returns\n    -------\n    PPFData\n        An object containing the cost values at each percentile and the corresponding percentiles.\n\n    Notes\n    -----\n    The empirical PPF is the inverse of the empirical CDF, mapping percentiles to samples values.\n    \"\"\"\n    p_values = np.linspace(start=0, stop=1, num=101)\n    sorted_data = np.sort(samples)\n    cumulative_probs = np.linspace(0, 1, len(sorted_data), endpoint=False)\n    cumulative_probs += 1 / len(sorted_data)\n\n    # Make the `p`==1 value actually for `p` == 0.999\n    cumulative_probs[-1] = 0.999\n    cost = np.interp(p_values, cumulative_probs, sorted_data)\n\n    # Add the `1-risk_probability` value to the array as the lower bound\n    lower_limit_index = len(cost[cost == 0]) - 1\n\n    cost[lower_limit_index] = samples[samples != 0].min()\n\n    return PPFData(cost=cost, p=p_values)\n</code></pre>"},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.get_histogram_data","title":"<code>get_histogram_data(data)</code>","text":"<p>Calculate histogram data, excluding zero values and normalizing by total data points.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>The data array for which to compute the histogram.</p> required <p>Returns:</p> Type Description <code>HistogramData</code> <p>An object containing the histogram bin edges and the normalized frequency.</p> Notes <p>The histogram is computed excluding zero values in the data. Frequencies are normalized by the total number of data points.</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def get_histogram_data(data: np.ndarray) -&gt; HistogramData:\n    \"\"\"\n    Calculate histogram data, excluding zero values and normalizing by total data points.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        The data array for which to compute the histogram.\n\n    Returns\n    -------\n    HistogramData\n        An object containing the histogram bin edges and the normalized frequency.\n\n    Notes\n    -----\n    The histogram is computed excluding zero values in the data.\n    Frequencies are normalized by the total number of data points.\n    \"\"\"\n    non_zero_data = data[data != 0]\n    num_bins = 40\n    hist, bin_edges = np.histogram(non_zero_data, bins=num_bins)\n    total_data_points = len(data)\n    frequency_including_zeros = hist / total_data_points\n    return HistogramData(cost=bin_edges, frequency=frequency_including_zeros)\n</code></pre>"},{"location":"quantitative/quantitative_probability/#darpi.quantitative.probability.get_aggregate_data","title":"<code>get_aggregate_data(risks)</code>","text":"<p>Generate aggregate sample data based on multiple risk scenarios.</p> <p>This function processes a dictionary of risk scenarios where each scenario has associated costs and a probability of occurrence. It generates sample data for each risk using a triangular distribution and aggregates these samples into a single dataset.</p> <p>Parameters:</p> Name Type Description Default <code>risks</code> <code>dict of str to dict of str to tuple or float</code> <p>A dictionary where the keys are risk names (str), and the values are dictionaries containing: - \"costs\": A tuple of three integers representing the minimum cost, mode, and maximum cost. - \"probability\": A float representing the probability of the risk occurring.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>An array of aggregated samples from all the provided risks, where each risk's samples are generated based on its triangular distribution and probability.</p> Notes <ul> <li>The triangular distribution is generated using the costs provided for each risk, where:</li> <li><code>a</code> is the minimum cost,</li> <li><code>c</code> is the mode (most likely cost),</li> <li><code>b</code> is the maximum cost.</li> <li>The number of samples generated for each risk is proportional to the risk's probability.</li> <li>The samples from all risks are summed element-wise to produce the final aggregated data.</li> </ul> Example <p>Example of <code>risks</code> dictionary structure:</p> <p>risks = {     \"Risk 1\": {\"costs\": (1000, 2000, 5000), \"probability\": 1},     \"Risk 2\": {\"costs\": (2000, 4000, 8000), \"probability\": 0.8},     \"Risk 3\": {\"costs\": (2800, 4000, 10000), \"probability\": 0.5}, } samples = get_aggregate_data(risks)</p> Source code in <code>darpi/quantitative/probability.py</code> <pre><code>def get_aggregate_data(\n    risks: dict[str, dict[str, tuple[int, int, int] | float]]\n) -&gt; np.ndarray:\n    \"\"\"\n    Generate aggregate sample data based on multiple risk scenarios.\n\n    This function processes a dictionary of risk scenarios where each scenario has associated costs\n    and a probability of occurrence. It generates sample data for each risk using a triangular distribution\n    and aggregates these samples into a single dataset.\n\n    Parameters\n    ----------\n    risks : dict of str to dict of str to tuple or float\n        A dictionary where the keys are risk names (str), and the values are dictionaries containing:\n        - \"costs\": A tuple of three integers representing the minimum cost, mode, and maximum cost.\n        - \"probability\": A float representing the probability of the risk occurring.\n\n    Returns\n    -------\n    np.ndarray\n        An array of aggregated samples from all the provided risks, where each risk's samples are\n        generated based on its triangular distribution and probability.\n\n    Notes\n    -----\n    - The triangular distribution is generated using the costs provided for each risk, where:\n      - `a` is the minimum cost,\n      - `c` is the mode (most likely cost),\n      - `b` is the maximum cost.\n    - The number of samples generated for each risk is proportional to the risk's probability.\n    - The samples from all risks are summed element-wise to produce the final aggregated data.\n\n    Example\n    -------\n    Example of `risks` dictionary structure:\n\n    &gt;&gt;&gt; risks = {\n    &gt;&gt;&gt;     \"Risk 1\": {\"costs\": (1000, 2000, 5000), \"probability\": 1},\n    &gt;&gt;&gt;     \"Risk 2\": {\"costs\": (2000, 4000, 8000), \"probability\": 0.8},\n    &gt;&gt;&gt;     \"Risk 3\": {\"costs\": (2800, 4000, 10000), \"probability\": 0.5},\n    &gt;&gt;&gt; }\n    &gt;&gt;&gt; samples = get_aggregate_data(risks)\n    \"\"\"\n    for risk, details in risks.items():\n        a, c, b = details[\"costs\"]\n        risk_probability = details[\"probability\"]\n        distribution = get_triangular_distribution(a, b, c)\n        data = get_samples(distribution=distribution, risk_probability=risk_probability)\n        risks[risk][\"samples\"] = data\n    samples = sum_samples([risk[\"samples\"] for risk in risks.values()])\n    return samples\n</code></pre>"},{"location":"quantitative/quantitative_tables/","title":"<code>tables</code>","text":""},{"location":"quantitative/quantitative_tables/#darpi.quantitative.tables.get_non_exceedance_table","title":"<code>get_non_exceedance_table(data)</code>","text":"<p>Generate a non-exceedance probability table from empirical data.</p> <p>This function calculates the empirical percent-point function (PPF) from the provided data and returns it as a pandas DataFrame. The PPF, also known as the quantile function, represents the inverse of the cumulative distribution function (CDF), mapping probability values to data values.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>An array of data points from which to compute the empirical PPF.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the non-exceedance probabilities and corresponding data values. The columns of the DataFrame correspond to the fields of the <code>PPFData</code> namedtuple, typically: - <code>cost</code>: The data values at each quantile. - <code>p</code>: The corresponding non-exceedance probabilities (percentiles).</p> Notes <ul> <li>The non-exceedance probability, <code>p</code>, represents the probability that a randomly selected   value from the distribution will be less than or equal to a given value.</li> <li>This function is particularly useful in risk analysis, where non-exceedance probabilities   are used to understand the likelihood of different cost outcomes.</li> </ul> Example <p>Example usage of <code>get_non_exceedance_table</code>:</p> <p>data = np.array([1000, 2000, 3000, 4000, 5000]) non_exceedance_table = get_non_exceedance_table(data) print(non_exceedance_table)</p> <p>This might output a DataFrame where each row represents a specific quantile and the corresponding data value at that quantile.</p> Source code in <code>darpi/quantitative/tables.py</code> <pre><code>def get_non_exceedance_table(data: np.ndarray) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate a non-exceedance probability table from empirical data.\n\n    This function calculates the empirical percent-point function (PPF) from the provided data and\n    returns it as a pandas DataFrame. The PPF, also known as the quantile function, represents the\n    inverse of the cumulative distribution function (CDF), mapping probability values to data values.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        An array of data points from which to compute the empirical PPF.\n\n    Returns\n    -------\n    pd.DataFrame\n        A DataFrame containing the non-exceedance probabilities and corresponding data values.\n        The columns of the DataFrame correspond to the fields of the `PPFData` namedtuple, typically:\n        - `cost`: The data values at each quantile.\n        - `p`: The corresponding non-exceedance probabilities (percentiles).\n\n    Notes\n    -----\n    - The non-exceedance probability, `p`, represents the probability that a randomly selected\n      value from the distribution will be less than or equal to a given value.\n    - This function is particularly useful in risk analysis, where non-exceedance probabilities\n      are used to understand the likelihood of different cost outcomes.\n\n    Example\n    -------\n    Example usage of `get_non_exceedance_table`:\n\n    &gt;&gt;&gt; data = np.array([1000, 2000, 3000, 4000, 5000])\n    &gt;&gt;&gt; non_exceedance_table = get_non_exceedance_table(data)\n    &gt;&gt;&gt; print(non_exceedance_table)\n\n    This might output a DataFrame where each row represents a specific quantile and the corresponding\n    data value at that quantile.\n\n    \"\"\"\n    ppf_data = get_empirical_ppf(data)\n    return pd.DataFrame({field: getattr(ppf_data, field) for field in ppf_data._fields})\n</code></pre>"}]}